{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_df.shape: (11783, 3, 128) | np.unique(y_df): [0 1 2 3] | np.unique(k_df): [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      "x_df_train.shape: (9426, 3, 128) | np.unique(y_df_train): [0 1 2 3]\n",
      "x_df_test.shape: (2357, 3, 128) | np.unique(y_df_test): [0 1 2 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open('splits/realworld_pamap_df.pkl', 'rb') as f:\n",
    "    x_df, y_df, k_df = pickle.load(f)\n",
    "\n",
    "print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)} | np.unique(k_df): {np.unique(k_df)}\\n')\n",
    "\n",
    "x_df_train, x_df_test, y_df_train, y_df_test = train_test_split(x_df, y_df, test_size=0.2, random_state=2710, stratify=y_df, shuffle=True)\n",
    "print(f'x_df_train.shape: {x_df_train.shape} | np.unique(y_df_train): {np.unique(y_df_train)}')\n",
    "print(f'x_df_test.shape: {x_df_test.shape} | np.unique(y_df_test): {np.unique(y_df_test)}\\n')\n",
    "\n",
    "train_df = {'samples': x_df_train, 'labels': y_df_train}\n",
    "test_df = {'samples': x_df_test, 'labels': y_df_test}\n",
    "\n",
    "torch.save(train_df, 'train_df.pt')\n",
    "torch.save(test_df, 'test_df.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_syn.shape: (5252, 3, 128) | np.unique(y_syn): [0 1 2 3] | np.unique(k_syn): [15 16 17 18 19 20]\n",
      "x_dp_map.shape: (1313, 3, 128) | np.unique(y_dp_map): [0 1 2 3] | np.unique(k_dp_map): [15 16 17 18 19 20]\n",
      "x_dp_te.shape: (240, 3, 128) | np.unique(y_dp_te): [0 1 2 3] | np.unique(k_dp_te): [15 16 17 18 19 20]\n",
      "\n",
      "x_syn_dom.shape: (864, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (216, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (40, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (900, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (225, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (40, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (1044, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (261, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (40, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (864, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (216, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (40, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (772, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (193, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (40, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (808, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (202, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (40, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('splits/realworld_pamap_rwpa0401.pkl', 'rb') as f:\n",
    "    x_syn, y_syn, k_syn = pickle.load(f)\n",
    "print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)} | np.unique(k_syn): {np.unique(k_syn)}')\n",
    "\n",
    "with open('splits/realworld_pamap_dp_map.pkl', 'rb') as f:\n",
    "    x_dp_map, y_dp_map, k_dp_map = pickle.load(f)\n",
    "print(f'x_dp_map.shape: {x_dp_map.shape} | np.unique(y_dp_map): {np.unique(y_dp_map)} | np.unique(k_dp_map): {np.unique(k_dp_map)}')\n",
    "\n",
    "with open('splits/realworld_pamap_dp_te.pkl', 'rb') as f:\n",
    "    x_dp_te, y_dp_te, k_dp_te = pickle.load(f)\n",
    "print(f'x_dp_te.shape: {x_dp_te.shape} | np.unique(y_dp_te): {np.unique(y_dp_te)} | np.unique(k_dp_te): {np.unique(k_dp_te)}\\n')\n",
    "\n",
    "for domain in np.unique(k_dp_map):\n",
    "    mask_syn = k_syn == domain\n",
    "    x_syn_dom, y_syn_dom = x_syn[mask_syn], y_syn[mask_syn]\n",
    "    print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "    mask_map = k_dp_map == domain\n",
    "    x_dp_map_dom, y_dp_map_dom = x_dp_map[mask_map], y_dp_map[mask_map]\n",
    "    print(f'x_dp_map_dom.shape: {x_dp_map_dom.shape} | np.unique(y_dp_map_dom): {np.unique(y_dp_map_dom)}')\n",
    "\n",
    "    mask_te = k_dp_te == domain\n",
    "    x_dp_te_dom, y_dp_te_dom = x_dp_te[mask_te], y_dp_te[mask_te]\n",
    "    print(f'x_dp_te_dom.shape: {x_dp_te_dom.shape} | np.unique(y_dp_te_dom): {np.unique(y_dp_te_dom)}\\n')    \n",
    "\n",
    "    train_syn = {'samples': x_syn_dom, 'labels': y_syn_dom}\n",
    "    test_syn = {'samples': x_syn_dom, 'labels': y_syn_dom}\n",
    "    train_dp = {'samples': x_dp_map_dom, 'labels': y_dp_map_dom}\n",
    "    test_dp = {'samples': x_dp_te_dom, 'labels': y_dp_te_dom}\n",
    "\n",
    "    torch.save(train_syn, f'train_syn_{domain}.pt')\n",
    "    torch.save(test_syn, f'test_syn_{domain}.pt')\n",
    "    torch.save(train_dp, f'train_dp_{domain}.pt')\n",
    "    torch.save(test_dp, f'test_dp_{domain}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stargan-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
