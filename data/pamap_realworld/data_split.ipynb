{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_df.shape: (1553, 3, 128) | np.unique(y_df): [0 1 2 3] | np.unique(k_df): [0 1 2 3 4 5]\n",
      "\n",
      "x_df_train.shape: (1553, 3, 128) | np.unique(y_df_train): [0 1 2 3]\n",
      "x_df_test.shape: (1553, 3, 128) | np.unique(y_df_test): [0 1 2 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open('splits/pamap_realworld_df.pkl', 'rb') as f:\n",
    "    x_df, y_df, k_df = pickle.load(f)\n",
    "\n",
    "print(f'x_df.shape: {x_df.shape} | np.unique(y_df): {np.unique(y_df)} | np.unique(k_df): {np.unique(k_df)}\\n')\n",
    "\n",
    "# x_df_train, x_df_test, y_df_train, y_df_test = train_test_split(x_df, y_df, test_size=0.2, random_state=2710, stratify=y_df, shuffle=True)\n",
    "x_df_train, x_df_test = x_df, x_df\n",
    "y_df_train, y_df_test = y_df, y_df\n",
    "print(f'x_df_train.shape: {x_df_train.shape} | np.unique(y_df_train): {np.unique(y_df_train)}')\n",
    "print(f'x_df_test.shape: {x_df_test.shape} | np.unique(y_df_test): {np.unique(y_df_test)}\\n')\n",
    "\n",
    "train_df = {'samples': x_df_train, 'labels': y_df_train}\n",
    "test_df = {'samples': x_df_test, 'labels': y_df_test}\n",
    "\n",
    "torch.save(train_df, 'train_df.pt')\n",
    "torch.save(test_df, 'test_df.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_syn.shape: (35164, 3, 128) | np.unique(y_syn): [0 1 2 3] | np.unique(k_syn): [ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "x_dp_map.shape: (8791, 3, 128) | np.unique(y_dp_map): [0 1 2 3] | np.unique(k_dp_map): [ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "x_dp_te.shape: (2992, 3, 128) | np.unique(y_dp_te): [0 1 2 3] | np.unique(k_dp_te): [ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "\n",
      "x_syn_dom.shape: (2700, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (675, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2400, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (600, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2716, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (679, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (1204, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (301, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2640, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (660, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2448, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (612, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (1568, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (392, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2788, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (697, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2476, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (619, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2328, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (582, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2696, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (674, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2524, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (631, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2540, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (635, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (1564, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (391, 3, 128) | np.unique(y_dp_map_dom): [0 1 3]\n",
      "x_dp_te_dom.shape: (192, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n",
      "x_syn_dom.shape: (2572, 3, 128) | np.unique(y_syn_dom): [0 1 2 3]\n",
      "x_dp_map_dom.shape: (643, 3, 128) | np.unique(y_dp_map_dom): [0 1 2 3]\n",
      "x_dp_te_dom.shape: (200, 3, 128) | np.unique(y_dp_te_dom): [0 1 2 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('splits/pamap_realworld_parw0401.pkl', 'rb') as f:\n",
    "    x_syn, y_syn, k_syn = pickle.load(f)\n",
    "print(f'x_syn.shape: {x_syn.shape} | np.unique(y_syn): {np.unique(y_syn)} | np.unique(k_syn): {np.unique(k_syn)}')\n",
    "\n",
    "with open('splits/pamap_realworld_dp_map.pkl', 'rb') as f:\n",
    "    x_dp_map, y_dp_map, k_dp_map = pickle.load(f)\n",
    "print(f'x_dp_map.shape: {x_dp_map.shape} | np.unique(y_dp_map): {np.unique(y_dp_map)} | np.unique(k_dp_map): {np.unique(k_dp_map)}')\n",
    "\n",
    "with open('splits/pamap_realworld_dp_te.pkl', 'rb') as f:\n",
    "    x_dp_te, y_dp_te, k_dp_te = pickle.load(f)\n",
    "print(f'x_dp_te.shape: {x_dp_te.shape} | np.unique(y_dp_te): {np.unique(y_dp_te)} | np.unique(k_dp_te): {np.unique(k_dp_te)}\\n')\n",
    "\n",
    "for domain in np.unique(k_dp_map):\n",
    "    mask_syn = k_syn == domain\n",
    "    x_syn_dom, y_syn_dom = x_syn[mask_syn], y_syn[mask_syn]\n",
    "    print(f'x_syn_dom.shape: {x_syn_dom.shape} | np.unique(y_syn_dom): {np.unique(y_syn_dom)}')\n",
    "\n",
    "    mask_map = k_dp_map == domain\n",
    "    x_dp_map_dom, y_dp_map_dom = x_dp_map[mask_map], y_dp_map[mask_map]\n",
    "    print(f'x_dp_map_dom.shape: {x_dp_map_dom.shape} | np.unique(y_dp_map_dom): {np.unique(y_dp_map_dom)}')\n",
    "\n",
    "    mask_te = k_dp_te == domain\n",
    "    x_dp_te_dom, y_dp_te_dom = x_dp_te[mask_te], y_dp_te[mask_te]\n",
    "    print(f'x_dp_te_dom.shape: {x_dp_te_dom.shape} | np.unique(y_dp_te_dom): {np.unique(y_dp_te_dom)}\\n')    \n",
    "\n",
    "    train_syn = {'samples': x_syn_dom, 'labels': y_syn_dom}\n",
    "    test_syn = {'samples': x_syn_dom, 'labels': y_syn_dom}\n",
    "    train_dp = {'samples': x_dp_map_dom, 'labels': y_dp_map_dom}\n",
    "    test_dp = {'samples': x_dp_te_dom, 'labels': y_dp_te_dom}\n",
    "\n",
    "    torch.save(train_syn, f'train_syn_{domain}.pt')\n",
    "    torch.save(test_syn, f'test_syn_{domain}.pt')\n",
    "    torch.save(train_dp, f'train_dp_{domain}.pt')\n",
    "    torch.save(test_dp, f'test_dp_{domain}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stargan-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
